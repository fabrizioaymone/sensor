{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHL Dataset Training and Inference with Dense and CNN Network\n",
    "\n",
    "Made by STMicroelectronics\n",
    "\n",
    "\n",
    "Authors: Fabrizio Maria Aymone, Danilo Pau\n",
    "\n",
    "contact: danilo.pau@st.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download SHL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://www.shl-dataset.org/wp-content/uploads/SHLDataset_preview_v1_part1.zip\n",
    "!7za x SHLDataset_preview_v1_part1.zip -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path related to the dataset folder\n",
    "\n",
    "root = './SHLDataset_preview_v1'\n",
    "\n",
    "# frame size and slide size\n",
    "\n",
    "window_size = 24\n",
    "slide = 12\n",
    "\n",
    "# sensors list\n",
    "list_sensors = ['label','acc_x','acc_y','acc_z','gy_x','gy_y','gy_z']\n",
    "\n",
    "# user dates\n",
    "user_dates_1 = ['220617', '260617','270617']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(position, user, user_dates):\n",
    "    data_tmp = []\n",
    "    label_tmp = []\n",
    "    for i in range(len(user_dates)):\n",
    "        data_path = root+'/User'+str(user)+'/'+user_dates[i]+'/'+position+'_Motion.txt' \n",
    "        label_path = root+'/User'+str(user)+'/'+user_dates[i]+'/Label.txt' \n",
    "        lb = pd.read_csv(label_path, sep = \" \", header = None)\n",
    "        df = pd.read_csv(data_path, sep = \" \", header = None)\n",
    "        data_tmp.append(df)\n",
    "        label_tmp.append(lb)\n",
    "    data = pd.concat([x for x in data_tmp], ignore_index = True)\n",
    "    labels = pd.concat([x for x in label_tmp], ignore_index = True)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "#import imblearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(position, user, user_dates):\n",
    "    \n",
    "    data, labels = load_data(position, user, user_dates)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['acc_x'] = data[1]\n",
    "    df['acc_y'] = data[2]\n",
    "    df['acc_z'] = data[3]\n",
    "    df['gy_x'] = data[4]\n",
    "    df['gy_y'] = data[5]\n",
    "    df['gy_z'] = data[6]\n",
    "    df['activity'] = labels[1]\n",
    "    df.drop(df.loc[df['activity']==0].index, inplace=True)\n",
    "    df = df.dropna()\n",
    "\n",
    "    label = sklearn.preprocessing.LabelEncoder()\n",
    "    df['label'] = label.fit_transform(df['activity'])\n",
    "    \n",
    "    X = df.loc[:,[\"acc_x\", \"acc_y\", \"acc_z\", \"gy_x\", \"gy_y\", \"gy_z\"]]\n",
    "    y = df.loc[:,\"label\"]\n",
    "    # over_sampler = imblearn.over_sampling.RandomOverSampler(random_state=42)\n",
    "    # X, y = over_sampler.fit_resample(df, df['label'])\n",
    "\n",
    "    #int16 symmetric quantization\n",
    "    max_acc  = max(np.abs(np.min(X[[\"acc_x\", \"acc_y\", \"acc_z\"]])), np.max(X[[\"acc_x\", \"acc_y\", \"acc_z\"]]))\n",
    "    max_gy =  max(np.abs(np.min(X[[\"gy_x\", \"gy_y\", \"gy_z\"]])), np.max(X[[\"gy_x\", \"gy_y\", \"gy_z\"]]))\n",
    "\n",
    "    scale_acc = 2*max_acc/(2**(16)-1)\n",
    "    scale_gy = 2*max_gy/(2**(16)-1)\n",
    "\n",
    "    X[[\"acc_x\", \"acc_y\", \"acc_z\"]] = np.round(X[[\"acc_x\", \"acc_y\", \"acc_z\"]]/scale_acc).astype(np.int16)\n",
    "    X[[\"gy_x\", \"gy_y\", \"gy_z\"]] = np.round(X[[\"gy_x\", \"gy_y\", \"gy_z\"]]/scale_gy).astype(np.int16)\n",
    "\n",
    "    df = pd.DataFrame(X)\n",
    "    df['label'] = y\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "from tensorflow import keras\n",
    "from itertools import chain\n",
    "import gc\n",
    "\n",
    "class CustomWindowGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, X, y, index_array=None, window_size=256, batch_size=64, slide=50, shuffle=True, pass_array=False):\n",
    "        \n",
    "        # X and y are lists of datasets e.g. if we have two datasets (X1, y1) and (X2, y2), X is [X1, X2] and y is [y1, y2]\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.slide = slide\n",
    "        self.shuffle = shuffle\n",
    "        self.index_array= np.array(list(chain(*[zip(np.repeat(idx, len(x)), np.arange(0, (len(x)-window_size+1), slide)) for idx, x in enumerate(X)])) if pass_array==False else index_array)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.index_array)\n",
    "        #self.epoch=1\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.index_array)\n",
    "        gc.collect()\n",
    "        keras.backend.clear_session()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        X_d = []\n",
    "        y_d = []\n",
    "        \n",
    "        for n, i in self.index_array[index*self.batch_size:index*self.batch_size + self.batch_size]:\n",
    "            \n",
    "            X_d.append([self.X[n][i:i+self.w]])\n",
    "            y_d.append(scipy.stats.mode(self.y[n][i:i+self.w])[0])\n",
    "        \n",
    "        return np.vstack(X_d), np.vstack(y_d)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index_array)//self.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_model(num_classes):\n",
    "\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    \n",
    "    model = keras.Sequential([\n",
    "            keras.layers.Input((24,6)),\n",
    "            keras.layers.Dense(128),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.Dense(64),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.Dense(128),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(32),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.ReLU(),\n",
    "            keras.layers.Dense(num_classes, activation = 'softmax'),\n",
    "            ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import *\n",
    "\n",
    "def get_dense_quantized_model(num_classes):\n",
    "\n",
    "        gc.collect()\n",
    "        keras.backend.clear_session()\n",
    "    \n",
    "    \n",
    "        #qkeras model\n",
    "\n",
    "        quantized_model = keras.Sequential([\n",
    "                        keras.layers.Input(shape=(24,6)),\n",
    "                        #QActivation(\"quantized_bits(16)\"),\n",
    "                        QDense(128, kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        QActivation(\"quantized_relu(8)\"),\n",
    "                        QDense(64, kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        QActivation(\"quantized_relu(8)\"),\n",
    "                        QDense(128, kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        QActivation(\"quantized_relu(8)\"),\n",
    "                        keras.layers.Flatten(),\n",
    "                        QDense(32, kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        QActivation(\"quantized_relu(8)\"),\n",
    "                        QDense(num_classes, kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.Activation('softmax'),\n",
    "                        ])\n",
    "\n",
    "        return quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn.model_selection\n",
    "# training hyperparameters\n",
    "\n",
    "batch_size = 256 \n",
    "epochs = 100\n",
    "\n",
    "def train(position, users, folder):\n",
    "\n",
    "        df = preprocess(position, users, folder) \n",
    "        X = df[[\"acc_x\", \"acc_y\", \"acc_z\", \"gy_x\", \"gy_y\", \"gy_z\"]].values.astype(np.float32)\n",
    "        y = df[[\"label\"]].values.astype(np.float32)\n",
    "\n",
    "        num_classes = len(np.unique(y))\n",
    "        print(\"Number of classes: \", num_classes)\n",
    "        \n",
    "        one_hot_y = keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "        kfold = sklearn.model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.2, train_size=0.8, random_state=1)\n",
    "        \n",
    "        fold = 1\n",
    "        \n",
    "        results_k = []\n",
    "        results_tflite = []\n",
    "        results_qk = []\n",
    "\n",
    "\n",
    "        index_array = np.array(list(chain(*[zip(np.repeat(idx, len(x)), np.arange(0, (len(x)-window_size+1), slide)) for idx, x in enumerate([X])])))\n",
    "        \n",
    "        y_index_array = []\n",
    "        for _, i in index_array:\n",
    "                y_index_array.append(scipy.stats.mode(y[i:i+window_size])[0])    \n",
    "        \n",
    "\n",
    "        train_index_array, test_index_array = sklearn.model_selection.train_test_split(index_array, test_size=0.2, random_state=42, shuffle=True, stratify=y_index_array)\n",
    "        \n",
    "        test_gen = CustomWindowGenerator([X], [one_hot_y], index_array=test_index_array, window_size=window_size, batch_size=batch_size, slide=slide, shuffle=True, pass_array=True)\n",
    "\n",
    "        X_test_lite = []\n",
    "        y_test_lite = []\n",
    "\n",
    "        for _,i in test_index_array:\n",
    "                X_test_lite.append(X[i:i+window_size])\n",
    "                y_test_lite.append(scipy.stats.mode(y[i:i+window_size])[0])\n",
    "        \n",
    "        X_test_lite = np.asarray(X_test_lite, dtype=np.float32)\n",
    "        y_test_lite = np.asarray(y_test_lite, dtype=np.int8)\n",
    "\n",
    "        # K fold validation 5 steps\n",
    "\n",
    "        for train_idx, val_idx in kfold.split(X = np.zeros(len(train_index_array)), y = y[train_index_array[:,1]]):\n",
    "                \n",
    "                train_gen = CustomWindowGenerator([X], [one_hot_y], index_array=train_index_array[train_idx], window_size=window_size, batch_size=batch_size, slide=slide, shuffle=True, pass_array=True)\n",
    "                val_gen = CustomWindowGenerator([X], [one_hot_y], index_array=train_index_array[val_idx], window_size=window_size, batch_size=2048, slide=slide, shuffle=True, pass_array=True)\n",
    "                \n",
    "                model = get_dense_model(num_classes)\n",
    "\n",
    "                model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy'])\n",
    "                \n",
    "                print(\"K fold validation step:\",fold)\n",
    "\n",
    "                # model callbacks\n",
    "                earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "\n",
    "                keras_models_dir = \"dense/keras_models/\"\n",
    "                os.makedirs(keras_models_dir, exist_ok=True)\n",
    "                mcp_path = keras_models_dir+'model_best_'+str(users)+'_'+position+'_k_fold_'+str(fold)+'.h5'\n",
    "                mcp_save = keras.callbacks.ModelCheckpoint(mcp_path, save_best_only=True, monitor='val_loss', mode='min')\n",
    "                \n",
    "                reduce_lr_loss = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_delta=0.0001, mode='auto', cooldown=0, min_lr=0)\n",
    "                \n",
    "                # model training\n",
    "                \n",
    "                model.fit(train_gen, validation_data=val_gen, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[earlyStopping, reduce_lr_loss, mcp_save])\n",
    "                \n",
    "                model = keras.models.load_model(mcp_path)\n",
    "\n",
    "                #evaluating the model on test data\n",
    "\n",
    "                result = model.evaluate(test_gen)\n",
    "                print(\"\\n\\n*****************************************keras model accuracy {} result: {}*****************************************\".format(fold, result[1]))\n",
    "                results_k.append(result[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                def representative_data_gen():\n",
    "                        repr_index_array = np.arange(0, len(X)-window_size+1, slide)\n",
    "                        np.random.shuffle(repr_index_array)\n",
    "                        for i in range(100):\n",
    "                                j = repr_index_array[i]\n",
    "                                yield [np.expand_dims(X[j:j+window_size], axis=0)]\n",
    "\n",
    "\n",
    "                # load best keras model to tensorflow liet converter for tflite conversion and quantization\n",
    "                converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "                converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "                converter.representative_dataset = representative_data_gen\n",
    "                # Ensure that if any ops can't be quantized, the converter throws an error\n",
    "                converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "                # Set the input and output tensors to float32 and int8 (APIs added in r2.3)\n",
    "                converter.inference_input_type = tf.float32\n",
    "                converter.inference_output_type = tf.int8\n",
    "\n",
    "                tflite_model_quant = converter.convert()\n",
    "\n",
    "                tflite_models_dir = \"dense/tflite_models/\"\n",
    "                os.makedirs(tflite_models_dir, exist_ok=True)\n",
    "                tflite_model_path = tflite_models_dir+\"tflite\"+'_'+str(position)+'_'+str(fold)+'.tflite'\n",
    "\n",
    "                with open(tflite_model_path, 'wb') as f:\n",
    "                        f.write(tflite_model_quant)\n",
    "        \n",
    "                # Input and output details\n",
    "\n",
    "                tflite_interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "                input_details = tflite_interpreter.get_input_details()\n",
    "                output_details = tflite_interpreter.get_output_details()\n",
    "                tflite_interpreter.resize_tensor_input(input_details[0]['index'], (X_test_lite.shape))\n",
    "                tflite_interpreter.allocate_tensors()\n",
    "\n",
    "                #quantize\n",
    "                scale, zero_point = input_details[0][\"quantization\"]\n",
    "\n",
    "                tflite_interpreter.set_tensor(input_details[0]['index'], X_test_lite)\n",
    "\n",
    "                tflite_interpreter.invoke()\n",
    "\n",
    "                scale, zero_point = output_details[0]['quantization']\n",
    "\n",
    "                tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "                y_pred = tflite_model_predictions\n",
    "                y_pred = (tflite_model_predictions.astype(np.int8))\n",
    "                result = sklearn.metrics.accuracy_score(np.squeeze(y_test_lite), y_pred.argmax(axis=1))\n",
    "                print(\"*****************************************TFlite model accuracy score: \"+str(result)+\"*****************************************\\n\\n\")\n",
    "                results_tflite.append(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                qmodel = get_dense_quantized_model(num_classes)\n",
    "\n",
    "                qmodel.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "                # model callbacks\n",
    "                earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
    "\n",
    "                qkeras_models_dir = \"dense/qkeras_models/\"\n",
    "                os.makedirs(qkeras_models_dir, exist_ok=True)\n",
    "                mcp_path = qkeras_models_dir+'model_best_'+str(users)+'_'+position+'_k_fold_'+str(fold)+'.h5'\n",
    "                mcp_save = keras.callbacks.ModelCheckpoint(mcp_path, save_best_only=True, monitor='val_loss', mode='min')\n",
    "                \n",
    "                reduce_lr_loss = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_delta=0.0001, mode='auto', cooldown=0, min_lr=0)\n",
    "                \n",
    "                # model training\n",
    "                \n",
    "                qmodel.fit(train_gen, validation_data=val_gen, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[earlyStopping, reduce_lr_loss, mcp_save])\n",
    "                \n",
    "                qmodel.load_weights(mcp_path)\n",
    "\n",
    "                #evaluating the model on test data\n",
    "\n",
    "                result = qmodel.evaluate(test_gen)\n",
    "                print(\"\\n\\n*****************************************qkeras model accuracy {} result: {}*****************************************\".format(fold, result[1]))\n",
    "                results_qk.append(result[1])\n",
    "                \n",
    "                fold+=1\n",
    "        \n",
    "        results_k, results_tflite, results_qk = np.asarray(results_k), np.asarray(results_tflite), np.asarray(results_qk)\n",
    "        os.makedirs(f\"./dense/results/{position}\", exist_ok=True)\n",
    "        np.save(f\"./dense/results/{position}/results_keras.npy\", results_k)\n",
    "        np.save(f\"./dense/results/{position}/results_tflite.npy\", results_tflite)\n",
    "        np.save(f\"./dense/results/{position}/results_qkeras.npy\", results_qk)\n",
    "        \n",
    "        return results_k, results_tflite, results_qk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"Hand\", 1, user_dates_1)\n",
    "train(\"Hips\", 1, user_dates_1)\n",
    "train(\"Torso\", 1, user_dates_1)\n",
    "train(\"Bag\", 1, user_dates_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(num_classes):\n",
    "\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input((24,6)),\n",
    "        keras.layers.Reshape((6,4,6)),\n",
    "        keras.layers.Conv2D(filters=8, kernel_size = (5,5), padding = \"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Conv2D(filters=8, kernel_size = (5,5), padding= \"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.MaxPool2D(pool_size = 2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.ReLU(),\n",
    "        keras.layers.Dense(num_classes, activation = 'softmax'),\n",
    "        ]) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import *\n",
    "\n",
    "def get_cnn_quantized_model(num_classes):\n",
    "\n",
    "        gc.collect()\n",
    "        keras.backend.clear_session()\n",
    "    \n",
    "    \n",
    "        #qkeras model\n",
    "\n",
    "        quantized_model = keras.Sequential([\n",
    "                        keras.layers.Input((24,6)),\n",
    "                        keras.layers.Reshape((6,4,6)),\n",
    "                        #QActivation(\"quantized_bits(16)\"),\n",
    "                        QConv2D(filters=8, kernel_size = (5,5), padding = \"same\", kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        QActivation(\"quantized_relu(8)\"),\n",
    "                        QConv2D(filters=8, kernel_size = (5,5), padding = \"same\", kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        QActivation(\"quantized_relu(8)\"),\n",
    "                        keras.layers.MaxPool2D(pool_size = 2),\n",
    "                        keras.layers.Flatten(),\n",
    "                        QDense(64, kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.BatchNormalization(),\n",
    "                        QActivation(\"quantized_relu(8)\"),\n",
    "                        QDense(num_classes, kernel_quantizer=\"quantized_bits(8)\"),\n",
    "                        keras.layers.Activation('softmax'),\n",
    "                        ])\n",
    "\n",
    "        return quantized_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# training hyperparameters\n",
    "\n",
    "batch_size = 64 \n",
    "epochs = 100\n",
    "\n",
    "def train(position, users, folder):\n",
    "\n",
    "        df = preprocess(position, users, folder) \n",
    "        X = df[[\"acc_x\", \"acc_y\", \"acc_z\", \"gy_x\", \"gy_y\", \"gy_z\"]].values.astype(np.float32)\n",
    "        y = df[[\"label\"]].values.astype(np.float32)\n",
    "\n",
    "        num_classes = len(np.unique(y))\n",
    "        print(\"Number of classes: \", num_classes)\n",
    "        \n",
    "        one_hot_y = keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "        kfold = sklearn.model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.2, train_size=0.8, random_state=1)\n",
    "        \n",
    "        fold = 1\n",
    "        \n",
    "        results_k = []\n",
    "        results_tflite = []\n",
    "        results_qk = []\n",
    "\n",
    "\n",
    "        index_array = np.array(list(chain(*[zip(np.repeat(idx, len(x)), np.arange(0, (len(x)-window_size+1), slide)) for idx, x in enumerate([X])])))\n",
    "        \n",
    "        y_index_array = []\n",
    "        for _, i in index_array:\n",
    "                y_index_array.append(scipy.stats.mode(y[i:i+window_size])[0])    \n",
    "        \n",
    "\n",
    "        train_index_array, test_index_array = sklearn.model_selection.train_test_split(index_array, test_size=0.2, random_state=42, shuffle=True, stratify=y_index_array)\n",
    "        \n",
    "        test_gen = CustomWindowGenerator([X], [one_hot_y], index_array=test_index_array, window_size=window_size, batch_size=batch_size, slide=slide, shuffle=True, pass_array=True)\n",
    "\n",
    "        X_test_lite = []\n",
    "        y_test_lite = []\n",
    "\n",
    "        for _,i in test_index_array:\n",
    "                X_test_lite.append(X[i:i+window_size])\n",
    "                y_test_lite.append(scipy.stats.mode(y[i:i+window_size])[0])\n",
    "        \n",
    "        X_test_lite = np.asarray(X_test_lite, dtype=np.float32)\n",
    "        y_test_lite = np.asarray(y_test_lite, dtype=np.int8)\n",
    "\n",
    "        # K fold validation 5 steps\n",
    "\n",
    "        for train_idx, val_idx in kfold.split(X = np.zeros(len(train_index_array)), y = y[train_index_array[:,1]]):\n",
    "                \n",
    "\n",
    "                train_gen = CustomWindowGenerator([X], [one_hot_y], index_array=train_index_array[train_idx], window_size=window_size, batch_size=batch_size, slide=slide, shuffle=True, pass_array=True)\n",
    "                val_gen = CustomWindowGenerator([X], [one_hot_y], index_array=train_index_array[val_idx], window_size=window_size, batch_size=batch_size, slide=slide, shuffle=True, pass_array=True)\n",
    "                \n",
    "                model = get_cnn_model(num_classes)\n",
    "\n",
    "                model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy'])\n",
    "                \n",
    "                print(\"K fold validation step:\",fold)\n",
    "\n",
    "                # model callbacks\n",
    "                earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
    "\n",
    "                keras_models_dir = \"cnn/keras_models/\"\n",
    "                os.makedirs(keras_models_dir, exist_ok=True)\n",
    "                mcp_path = keras_models_dir+'model_best_'+str(users)+'_'+position+'_k_fold_'+str(fold)+'.h5'\n",
    "                mcp_save = keras.callbacks.ModelCheckpoint(mcp_path, save_best_only=True, monitor='val_loss', mode='min')\n",
    "                \n",
    "                reduce_lr_loss = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_delta=0.0001, mode='auto', cooldown=0, min_lr=0)\n",
    "                \n",
    "                # model training\n",
    "                \n",
    "                model.fit(train_gen, validation_data=val_gen, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[earlyStopping, reduce_lr_loss, mcp_save])\n",
    "                \n",
    "                model = keras.models.load_model(mcp_path)\n",
    "\n",
    "                #evaluating the model on test data\n",
    "\n",
    "                result = model.evaluate(test_gen)\n",
    "                print(\"\\n\\n*****************************************keras model accuracy {} result: {}*****************************************\".format(fold, result[1]))\n",
    "                results_k.append(result[1])\n",
    "\n",
    "\n",
    "                        \n",
    "\n",
    "\n",
    "\n",
    "                def representative_data_gen():\n",
    "                        repr_index_array = np.arange(0, len(X)-window_size+1, slide)\n",
    "                        np.random.shuffle(repr_index_array)\n",
    "                        for i in range(100):\n",
    "                                j = repr_index_array[i]\n",
    "                                yield [np.expand_dims(X[j:j+window_size], axis=0)]\n",
    "\n",
    "\n",
    "                # load best keras model to tensorflow liet converter for tflite conversion and quantization\n",
    "                converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "                converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "                converter.representative_dataset = representative_data_gen\n",
    "                # Ensure that if any ops can't be quantized, the converter throws an error\n",
    "                converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "                # Set the input and output tensors to float32 and int8 (APIs added in r2.3)\n",
    "                converter.inference_input_type = tf.float32\n",
    "                converter.inference_output_type = tf.int8\n",
    "\n",
    "                tflite_model_quant = converter.convert()\n",
    "\n",
    "                tflite_models_dir = \"cnn/tflite_models/\"\n",
    "                os.makedirs(tflite_models_dir, exist_ok=True)\n",
    "                tflite_model_path = tflite_models_dir+\"tflite\"+'_'+str(position)+'_'+str(fold)+'.tflite'\n",
    "\n",
    "                with open(tflite_model_path, 'wb') as f:\n",
    "                        f.write(tflite_model_quant)\n",
    "        \n",
    "                # Input and output details\n",
    "\n",
    "                tflite_interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "                input_details = tflite_interpreter.get_input_details()\n",
    "                output_details = tflite_interpreter.get_output_details()\n",
    "                tflite_interpreter.resize_tensor_input(input_details[0]['index'], (X_test_lite.shape))\n",
    "                tflite_interpreter.allocate_tensors()\n",
    "\n",
    "                #quantize\n",
    "                scale, zero_point = input_details[0][\"quantization\"]\n",
    "\n",
    "                tflite_interpreter.set_tensor(input_details[0]['index'], X_test_lite)\n",
    "\n",
    "                tflite_interpreter.invoke()\n",
    "\n",
    "                scale, zero_point = output_details[0]['quantization']\n",
    "\n",
    "                tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "                y_pred = tflite_model_predictions\n",
    "                y_pred = (tflite_model_predictions.astype(np.int8))\n",
    "                result = sklearn.metrics.accuracy_score(np.squeeze(y_test_lite), y_pred.argmax(axis=1))\n",
    "                print(\"*****************************************TFlite model accuracy score: \"+str(result)+\"*****************************************\\n\\n\")\n",
    "                results_tflite.append(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                qmodel = get_cnn_quantized_model(num_classes)\n",
    "\n",
    "                qmodel.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "                # model callbacks\n",
    "                earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "\n",
    "                qkeras_models_dir = \"cnn/qkeras_models/\"\n",
    "                os.makedirs(qkeras_models_dir, exist_ok=True)\n",
    "                mcp_path = qkeras_models_dir+'model_best_'+str(users)+'_'+position+'_k_fold_'+str(fold)+'.h5'\n",
    "                mcp_save = keras.callbacks.ModelCheckpoint(mcp_path, save_best_only=True, monitor='val_loss', mode='min')\n",
    "                \n",
    "                reduce_lr_loss = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_delta=0.0001, mode='auto', cooldown=0, min_lr=0)\n",
    "                \n",
    "                # model training\n",
    "                \n",
    "                qmodel.fit(train_gen, validation_data=val_gen, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[earlyStopping, reduce_lr_loss, mcp_save])\n",
    "                \n",
    "                qmodel.load_weights(mcp_path)\n",
    "\n",
    "                #evaluating the model on test data\n",
    "\n",
    "                result = qmodel.evaluate(test_gen)\n",
    "                print(\"\\n\\n*****************************************qkeras model accuracy {} result: {}*****************************************\".format(fold, result[1]))\n",
    "                results_qk.append(result[1])\n",
    "                \n",
    "                fold+=1\n",
    "                \n",
    "\n",
    "        results_k, results_tflite, results_qk = np.asarray(results_k), np.asarray(results_tflite), np.asarray(results_qk)\n",
    "        os.makedirs(f\"./cnn/results/{position}\", exist_ok=True)\n",
    "        np.save(f\"./cnn/results/{position}/results_keras.npy\", results_k)\n",
    "        np.save(f\"./cnn/results/{position}/results_tflite.npy\", results_tflite)\n",
    "        np.save(f\"./cnn/results/{position}/results_qkeras.npy\", results_qk)\n",
    "\n",
    "        return results_k, results_tflite, results_qk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\"Hand\", 1, user_dates_1)\n",
    "train(\"Hips\", 1, user_dates_1)\n",
    "train(\"Torso\", 1, user_dates_1)\n",
    "train(\"Bag\", 1, user_dates_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"./dense/keras_models/model_best_1_Hand_k_fold_1.h5\"\n",
    "model = keras.models.load_model(example)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"./dense/qkeras_models/model_best_1_Hand_k_fold_1.h5\"\n",
    "qmodel = get_dense_quantized_model(8) #the classes are 8\n",
    "qmodel.load_weights(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_results = {\"Hand\":[], \"Hips\":[], \"Torso\":[], \"Bag\":[]}\n",
    "\n",
    "for pos in dense_results.keys():\n",
    "    dense_results[pos].append([np.load(f\"./dense/results/{pos}/results_keras.npy\"), np.load(f\"./dense/results/{pos}/results_tflite.npy\"), np.load(f\"./dense/results/{pos}/results_qkeras.npy\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science','ieee', 'no-latex'])\n",
    "\n",
    "positions = [\"Hand\", \"Hips\", \"Torso\", \"Bag\"]\n",
    "def plot_metrics(results, title):\n",
    "\n",
    "    fig, axs = plt.subplots(1, len(positions), figsize=(16, 4))\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "    for ax, pos in enumerate(positions):\n",
    "        keras_acc = np.asarray(results[pos])[0][0]\n",
    "        tflite_acc = np.asarray(results[pos])[0][1]\n",
    "        qkeras_acc = np.asarray(results[pos])[0][2]\n",
    "\n",
    "        x = [0, 1, 2]\n",
    "        labels = [\"Keras\", \"TFlite\", \"QKeras\"]\n",
    "\n",
    "        axs[ax].errorbar(x, [np.average(keras_acc), np.average(tflite_acc), np.average(qkeras_acc)], yerr=[np.std(keras_acc), np.std(tflite_acc), np.std(qkeras_acc)], capsize=3, fmt=\"r--o\", ecolor = \"black\")\n",
    "        print(np.average(keras_acc), np.average(tflite_acc), np.average(qkeras_acc), np.std(keras_acc), np.std(tflite_acc), np.std(qkeras_acc))\n",
    "        axs[ax].set_xticks(x, labels, rotation=\"horizontal\")\n",
    "        axs[ax].set_title(pos)\n",
    "    fig.suptitle(title, fontsize=16, y=0.95)\n",
    "    fig.text(0.09, 0.5, 'Accuracy', va='center', rotation='vertical', fontsize=10)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(dense_results, \"Dense\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"./cnn/keras_models/model_best_1_Hand_k_fold_1.h5\"\n",
    "model = keras.models.load_model(example)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"./cnn/qkeras_models/model_best_1_Hand_k_fold_1.h5\"\n",
    "qmodel = get_cnn_quantized_model(8) #the classes are 8\n",
    "qmodel.load_weights(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_results = {\"Hand\":[], \"Hips\":[], \"Torso\":[], \"Bag\":[]}\n",
    "\n",
    "for pos in cnn_results.keys():\n",
    "    cnn_results[pos].append([np.load(f\"./cnn/results/{pos}/results_keras.npy\"), np.load(f\"./cnn/results/{pos}/results_tflite.npy\"), np.load(f\"./cnn/results/{pos}/results_qkeras.npy\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(cnn_results, \"CNN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensorml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
